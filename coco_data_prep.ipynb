{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/\n",
    "#https://github.com/ismailuddin/gradcam-tensorflow-2/blob/master/notebooks/GradCam.ipynb\n",
    "#https://gist.github.com/RaphaelMeudec/e9a805fa82880876f8d89766f0690b54\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from torchvision.models import vgg19, resnet50\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gc\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Scale(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "    ]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset class to pre-process the images and return the images and labels to feed into the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetProcessing(Dataset):\n",
    "    def __init__(self, data_path, img_path, ann_path, transform=None, dataType = 'train'):\n",
    "        \n",
    "        self.ann_path = os.path.join(data_path, \"annotations\", ann_path)\n",
    "        self.img_path = os.path.join(data_path, img_path)       \n",
    "\n",
    "        coco=COCO(self.ann_path)\n",
    "        catIDs = coco.getCatIds()\n",
    "        cats = coco.loadCats(catIDs)\n",
    "\n",
    "        annIDs = coco.getAnnIds(catIds=catIDs, iscrowd = False)\n",
    "        anns = coco.loadAnns(ids=annIDs)        \n",
    "\n",
    "        imgIDs = []\n",
    "        labelIDs = []\n",
    "        for i in range(0,len(anns)):\n",
    "            imgIDs.append(anns[i]['image_id'])\n",
    "            labelIDs.append(anns[i]['category_id'])\n",
    "\n",
    "        imgIDs = np.array(imgIDs)\n",
    "        labelIDs = np.array(labelIDs)\n",
    "        uniqueImgIDs = np.unique(imgIDs)\n",
    "\n",
    "        uniqueTargetLabels = []\n",
    "        orderedLabels = np.arange(0,len(catIDs)).astype(np.uint8)\n",
    "        for i in tqdm(range(0,len(uniqueImgIDs))):\n",
    "            targetLabels = labelIDs[imgIDs == uniqueImgIDs[i]]\n",
    "            uniqueLabels = np.unique(targetLabels)\n",
    "            actualLabels = np.zeros(len(uniqueLabels))\n",
    "            for j in range(0,len(uniqueLabels)):\n",
    "                actualLabels[j] = orderedLabels[catIDs == uniqueLabels[j]]\n",
    "            uniqueTargetLabels.append(actualLabels)\n",
    "\n",
    "        uniqueImgIDs = uniqueImgIDs.tolist()\n",
    "        imgs = coco.loadImgs(ids=uniqueImgIDs)\n",
    "\n",
    "        imgFilenames = []\n",
    "        labels = np.zeros((len(imgs),len(catIDs)))\n",
    "        for i in range(0,len(imgs)):\n",
    "            imgFilenames.append(imgs[i]['file_name'])    \n",
    "            uniqueTargetLabels[i] = uniqueTargetLabels[i].astype(np.uint8)        \n",
    "            labels[i,uniqueTargetLabels[i]] = 1\n",
    "\n",
    "        if dataType != 'test':\n",
    "            train_x, val_x, train_y, val_y = train_test_split(imgFilenames, labels, test_size=0.33, random_state=2021)\n",
    "            if dataType == 'train':\n",
    "                self.img_filename = train_x\n",
    "                self.label = train_y\n",
    "            elif dataType == 'val':\n",
    "                self.img_filename = val_x\n",
    "                self.label = val_y\n",
    "        else:\n",
    "            self.img_filename = imgFilenames\n",
    "            self.label = labels\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_path, self.img_filename[index]))\n",
    "        img = img.convert('RGB')\n",
    "        img = np.array(img)\n",
    "\n",
    "        def resize_with_padding(im, desired_size = 224):\n",
    "            \"\"\" Resize Image into a square based on desired_size with padding\n",
    "            \"\"\"\n",
    "            old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "\n",
    "            ratio = float(desired_size)/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "            # new_size should be in (width, height) format\n",
    "\n",
    "            im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "\n",
    "            delta_w = desired_size - new_size[1]\n",
    "            delta_h = desired_size - new_size[0]\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "            color = [0, 0, 0]\n",
    "            new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "                value=color)\n",
    "            return new_im\n",
    "\n",
    "        img = resize_with_padding(img)\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.from_numpy(self.label[index])\n",
    "                \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/media/HD1/sriram/data/coco\"\n",
    "\n",
    "TRAIN_IMG_PATH = \"train2017\"\n",
    "TRAIN_ANN_PATH = \"instances_train2017.json\"\n",
    "\n",
    "TEST_IMG_PATH = \"val2017\"\n",
    "TEST_ANN_PATH = \"instances_val2017.json\"\n",
    "\n",
    "MODEL_PATH_FULL = \"/media/HD1/sriram/models/vgg_train_coco_80classes.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=8.94s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117266/117266 [00:21<00:00, 5513.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=8.51s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117266/117266 [00:21<00:00, 5467.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the training set and validation set\n",
    "train_set = DatasetProcessing(DATA_PATH, TRAIN_IMG_PATH, TRAIN_ANN_PATH, transform = transformations, dataType = 'train')\n",
    "val_set = DatasetProcessing(DATA_PATH, TRAIN_IMG_PATH, TRAIN_ANN_PATH, transform = transformations, dataType = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data loaders for training set and validation set\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size = batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight False\n",
      "features.0.bias False\n",
      "features.2.weight False\n",
      "features.2.bias False\n",
      "features.5.weight False\n",
      "features.5.bias False\n",
      "features.7.weight False\n",
      "features.7.bias False\n",
      "features.10.weight False\n",
      "features.10.bias False\n",
      "features.12.weight False\n",
      "features.12.bias False\n",
      "features.14.weight False\n",
      "features.14.bias False\n",
      "features.16.weight False\n",
      "features.16.bias False\n",
      "features.19.weight False\n",
      "features.19.bias False\n",
      "features.21.weight False\n",
      "features.21.bias False\n",
      "features.23.weight False\n",
      "features.23.bias False\n",
      "features.25.weight False\n",
      "features.25.bias False\n",
      "features.28.weight False\n",
      "features.28.bias False\n",
      "features.30.weight False\n",
      "features.30.bias False\n",
      "features.32.weight False\n",
      "features.32.bias False\n",
      "features.34.weight False\n",
      "features.34.bias False\n",
      "classifier.0.weight False\n",
      "classifier.0.bias False\n",
      "classifier.3.weight False\n",
      "classifier.3.bias False\n",
      "classifier.6.weight True\n",
      "classifier.6.bias True\n"
     ]
    }
   ],
   "source": [
    "# Modify the VGG16 base model to fit the COCO data via transfer learning.\n",
    "num_classes = 80\n",
    "model = vgg19(pretrained = True)\n",
    "\n",
    "# Transfer learning of VGG16 for MSCOCO dataset with 80 classes.\n",
    "# Train only the last FC layer. Freeze the parameters in the other layers.\n",
    "for param in model.named_parameters():\n",
    "    param[1].requires_grad = False\n",
    "\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "for param in model.named_parameters():\n",
    "    print(param[0],param[1].requires_grad)\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer and loss function\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sriram/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.0011897034 \t Training Accuracy: 17.93 \tValidation Loss: 0.1901787218 \tValidation Accuracy 16.76\n",
      "Validation loss decreased (inf --> 0.1901787218).\n",
      "Epoch: 2 \tTraining Loss: 0.0006163475 \t Training Accuracy: 15.77 \tValidation Loss: 0.1518297902 \tValidation Accuracy 16.49\n",
      "Validation loss decreased (0.1901787218 --> 0.1518297902).\n",
      "Epoch: 3 \tTraining Loss: 0.0005406772 \t Training Accuracy: 15.88 \tValidation Loss: 0.1374833527 \tValidation Accuracy 16.50\n",
      "Validation loss decreased (0.1518297902 --> 0.1374833527).\n",
      "Epoch: 4 \tTraining Loss: 0.0005060062 \t Training Accuracy: 16.13 \tValidation Loss: 0.1291879602 \tValidation Accuracy 16.74\n",
      "Validation loss decreased (0.1374833527 --> 0.1291879602).\n",
      "Epoch: 5 \tTraining Loss: 0.0004830777 \t Training Accuracy: 16.38 \tValidation Loss: 0.1234340292 \tValidation Accuracy 17.21\n",
      "Validation loss decreased (0.1291879602 --> 0.1234340292).\n",
      "Epoch: 6 \tTraining Loss: 0.0004663182 \t Training Accuracy: 16.85 \tValidation Loss: 0.1190127767 \tValidation Accuracy 17.97\n",
      "Validation loss decreased (0.1234340292 --> 0.1190127767).\n",
      "Epoch: 7 \tTraining Loss: 0.0004523280 \t Training Accuracy: 17.44 \tValidation Loss: 0.1154388079 \tValidation Accuracy 18.98\n",
      "Validation loss decreased (0.1190127767 --> 0.1154388079).\n",
      "Epoch: 8 \tTraining Loss: 0.0004408293 \t Training Accuracy: 18.29 \tValidation Loss: 0.1124517519 \tValidation Accuracy 20.17\n",
      "Validation loss decreased (0.1154388079 --> 0.1124517519).\n",
      "Epoch: 9 \tTraining Loss: 0.0004305663 \t Training Accuracy: 19.10 \tValidation Loss: 0.1099095131 \tValidation Accuracy 21.47\n",
      "Validation loss decreased (0.1124517519 --> 0.1099095131).\n",
      "Epoch: 10 \tTraining Loss: 0.0004217269 \t Training Accuracy: 19.97 \tValidation Loss: 0.1076977355 \tValidation Accuracy 22.67\n",
      "Validation loss decreased (0.1099095131 --> 0.1076977355).\n",
      "Epoch: 11 \tTraining Loss: 0.0004147049 \t Training Accuracy: 20.84 \tValidation Loss: 0.1057555768 \tValidation Accuracy 23.86\n",
      "Validation loss decreased (0.1076977355 --> 0.1057555768).\n",
      "Epoch: 12 \tTraining Loss: 0.0004074035 \t Training Accuracy: 21.71 \tValidation Loss: 0.1040283750 \tValidation Accuracy 24.91\n",
      "Validation loss decreased (0.1057555768 --> 0.1040283750).\n",
      "Epoch: 13 \tTraining Loss: 0.0004013659 \t Training Accuracy: 22.46 \tValidation Loss: 0.1024890854 \tValidation Accuracy 25.88\n",
      "Validation loss decreased (0.1040283750 --> 0.1024890854).\n",
      "Epoch: 14 \tTraining Loss: 0.0003960708 \t Training Accuracy: 23.18 \tValidation Loss: 0.1010927103 \tValidation Accuracy 26.76\n",
      "Validation loss decreased (0.1024890854 --> 0.1010927103).\n",
      "Epoch: 15 \tTraining Loss: 0.0003910518 \t Training Accuracy: 23.99 \tValidation Loss: 0.0998288528 \tValidation Accuracy 27.67\n",
      "Validation loss decreased (0.1010927103 --> 0.0998288528).\n",
      "Epoch: 16 \tTraining Loss: 0.0003862708 \t Training Accuracy: 24.60 \tValidation Loss: 0.0986841797 \tValidation Accuracy 28.50\n",
      "Validation loss decreased (0.0998288528 --> 0.0986841797).\n",
      "Epoch: 17 \tTraining Loss: 0.0003818337 \t Training Accuracy: 25.32 \tValidation Loss: 0.0976265337 \tValidation Accuracy 29.22\n",
      "Validation loss decreased (0.0986841797 --> 0.0976265337).\n",
      "Epoch: 18 \tTraining Loss: 0.0003781571 \t Training Accuracy: 25.87 \tValidation Loss: 0.0966560211 \tValidation Accuracy 29.98\n",
      "Validation loss decreased (0.0976265337 --> 0.0966560211).\n",
      "Epoch: 19 \tTraining Loss: 0.0003747540 \t Training Accuracy: 26.42 \tValidation Loss: 0.0957529944 \tValidation Accuracy 30.69\n",
      "Validation loss decreased (0.0966560211 --> 0.0957529944).\n",
      "Epoch: 20 \tTraining Loss: 0.0003714749 \t Training Accuracy: 27.03 \tValidation Loss: 0.0949195751 \tValidation Accuracy 31.33\n",
      "Validation loss decreased (0.0957529944 --> 0.0949195751).\n",
      "Epoch: 21 \tTraining Loss: 0.0003685731 \t Training Accuracy: 27.48 \tValidation Loss: 0.0941483940 \tValidation Accuracy 31.92\n",
      "Validation loss decreased (0.0949195751 --> 0.0941483940).\n",
      "Epoch: 22 \tTraining Loss: 0.0003659275 \t Training Accuracy: 27.96 \tValidation Loss: 0.0934141074 \tValidation Accuracy 32.51\n",
      "Validation loss decreased (0.0941483940 --> 0.0934141074).\n",
      "Epoch: 23 \tTraining Loss: 0.0003629783 \t Training Accuracy: 28.55 \tValidation Loss: 0.0927355642 \tValidation Accuracy 33.04\n",
      "Validation loss decreased (0.0934141074 --> 0.0927355642).\n",
      "Epoch: 24 \tTraining Loss: 0.0003605145 \t Training Accuracy: 28.87 \tValidation Loss: 0.0921045952 \tValidation Accuracy 33.56\n",
      "Validation loss decreased (0.0927355642 --> 0.0921045952).\n",
      "Epoch: 25 \tTraining Loss: 0.0003584823 \t Training Accuracy: 29.26 \tValidation Loss: 0.0915137070 \tValidation Accuracy 34.11\n",
      "Validation loss decreased (0.0921045952 --> 0.0915137070).\n",
      "Epoch: 26 \tTraining Loss: 0.0003561316 \t Training Accuracy: 29.78 \tValidation Loss: 0.0909523045 \tValidation Accuracy 34.55\n",
      "Validation loss decreased (0.0915137070 --> 0.0909523045).\n",
      "Epoch: 27 \tTraining Loss: 0.0003540008 \t Training Accuracy: 30.08 \tValidation Loss: 0.0904270062 \tValidation Accuracy 35.04\n",
      "Validation loss decreased (0.0909523045 --> 0.0904270062).\n",
      "Epoch: 28 \tTraining Loss: 0.0003519346 \t Training Accuracy: 30.56 \tValidation Loss: 0.0899259744 \tValidation Accuracy 35.50\n",
      "Validation loss decreased (0.0904270062 --> 0.0899259744).\n",
      "Epoch: 29 \tTraining Loss: 0.0003500626 \t Training Accuracy: 30.90 \tValidation Loss: 0.0894578169 \tValidation Accuracy 35.91\n",
      "Validation loss decreased (0.0899259744 --> 0.0894578169).\n",
      "Epoch: 30 \tTraining Loss: 0.0003485195 \t Training Accuracy: 31.26 \tValidation Loss: 0.0890136881 \tValidation Accuracy 36.31\n",
      "Validation loss decreased (0.0894578169 --> 0.0890136881).\n",
      "Epoch: 31 \tTraining Loss: 0.0003470961 \t Training Accuracy: 31.56 \tValidation Loss: 0.0885844924 \tValidation Accuracy 36.68\n",
      "Validation loss decreased (0.0890136881 --> 0.0885844924).\n",
      "Epoch: 32 \tTraining Loss: 0.0003454588 \t Training Accuracy: 31.85 \tValidation Loss: 0.0881767059 \tValidation Accuracy 37.03\n",
      "Validation loss decreased (0.0885844924 --> 0.0881767059).\n",
      "Epoch: 33 \tTraining Loss: 0.0003438736 \t Training Accuracy: 32.18 \tValidation Loss: 0.0877996825 \tValidation Accuracy 37.44\n",
      "Validation loss decreased (0.0881767059 --> 0.0877996825).\n",
      "Epoch: 34 \tTraining Loss: 0.0003427090 \t Training Accuracy: 32.52 \tValidation Loss: 0.0874253769 \tValidation Accuracy 37.75\n",
      "Validation loss decreased (0.0877996825 --> 0.0874253769).\n",
      "Epoch: 35 \tTraining Loss: 0.0003413325 \t Training Accuracy: 32.73 \tValidation Loss: 0.0870685244 \tValidation Accuracy 38.06\n",
      "Validation loss decreased (0.0874253769 --> 0.0870685244).\n",
      "Epoch: 36 \tTraining Loss: 0.0003397444 \t Training Accuracy: 33.02 \tValidation Loss: 0.0867394223 \tValidation Accuracy 38.43\n",
      "Validation loss decreased (0.0870685244 --> 0.0867394223).\n",
      "Epoch: 37 \tTraining Loss: 0.0003385921 \t Training Accuracy: 33.29 \tValidation Loss: 0.0864200562 \tValidation Accuracy 38.74\n",
      "Validation loss decreased (0.0867394223 --> 0.0864200562).\n",
      "Epoch: 38 \tTraining Loss: 0.0003376017 \t Training Accuracy: 33.57 \tValidation Loss: 0.0861207033 \tValidation Accuracy 39.04\n",
      "Validation loss decreased (0.0864200562 --> 0.0861207033).\n",
      "Epoch: 39 \tTraining Loss: 0.0003364254 \t Training Accuracy: 33.83 \tValidation Loss: 0.0858276839 \tValidation Accuracy 39.32\n",
      "Validation loss decreased (0.0861207033 --> 0.0858276839).\n",
      "Epoch: 40 \tTraining Loss: 0.0003354860 \t Training Accuracy: 34.01 \tValidation Loss: 0.0855469439 \tValidation Accuracy 39.65\n",
      "Validation loss decreased (0.0858276839 --> 0.0855469439).\n",
      "Epoch: 41 \tTraining Loss: 0.0003341896 \t Training Accuracy: 34.36 \tValidation Loss: 0.0852735024 \tValidation Accuracy 39.93\n",
      "Validation loss decreased (0.0855469439 --> 0.0852735024).\n",
      "Epoch: 42 \tTraining Loss: 0.0003330048 \t Training Accuracy: 34.58 \tValidation Loss: 0.0850118324 \tValidation Accuracy 40.19\n",
      "Validation loss decreased (0.0852735024 --> 0.0850118324).\n",
      "Epoch: 43 \tTraining Loss: 0.0003324549 \t Training Accuracy: 34.76 \tValidation Loss: 0.0847548173 \tValidation Accuracy 40.42\n",
      "Validation loss decreased (0.0850118324 --> 0.0847548173).\n",
      "Epoch: 44 \tTraining Loss: 0.0003315848 \t Training Accuracy: 34.99 \tValidation Loss: 0.0845143725 \tValidation Accuracy 40.66\n",
      "Validation loss decreased (0.0847548173 --> 0.0845143725).\n",
      "Epoch: 45 \tTraining Loss: 0.0003305283 \t Training Accuracy: 35.12 \tValidation Loss: 0.0842770702 \tValidation Accuracy 40.89\n",
      "Validation loss decreased (0.0845143725 --> 0.0842770702).\n",
      "Epoch: 46 \tTraining Loss: 0.0003297920 \t Training Accuracy: 35.26 \tValidation Loss: 0.0840545932 \tValidation Accuracy 41.11\n",
      "Validation loss decreased (0.0842770702 --> 0.0840545932).\n",
      "Epoch: 47 \tTraining Loss: 0.0003286950 \t Training Accuracy: 35.61 \tValidation Loss: 0.0838408438 \tValidation Accuracy 41.34\n",
      "Validation loss decreased (0.0840545932 --> 0.0838408438).\n",
      "Epoch: 48 \tTraining Loss: 0.0003278884 \t Training Accuracy: 35.73 \tValidation Loss: 0.0836342516 \tValidation Accuracy 41.54\n",
      "Validation loss decreased (0.0838408438 --> 0.0836342516).\n",
      "Epoch: 49 \tTraining Loss: 0.0003272858 \t Training Accuracy: 35.83 \tValidation Loss: 0.0834352241 \tValidation Accuracy 41.77\n",
      "Validation loss decreased (0.0836342516 --> 0.0834352241).\n",
      "Epoch: 50 \tTraining Loss: 0.0003264654 \t Training Accuracy: 36.07 \tValidation Loss: 0.0832372557 \tValidation Accuracy 41.94\n",
      "Validation loss decreased (0.0834352241 --> 0.0832372557).\n",
      "Epoch: 51 \tTraining Loss: 0.0003259787 \t Training Accuracy: 36.32 \tValidation Loss: 0.0830448277 \tValidation Accuracy 42.12\n",
      "Validation loss decreased (0.0832372557 --> 0.0830448277).\n",
      "Epoch: 52 \tTraining Loss: 0.0003250084 \t Training Accuracy: 36.40 \tValidation Loss: 0.0828651789 \tValidation Accuracy 42.31\n",
      "Validation loss decreased (0.0830448277 --> 0.0828651789).\n",
      "Epoch: 53 \tTraining Loss: 0.0003244969 \t Training Accuracy: 36.57 \tValidation Loss: 0.0826842008 \tValidation Accuracy 42.48\n",
      "Validation loss decreased (0.0828651789 --> 0.0826842008).\n",
      "Epoch: 54 \tTraining Loss: 0.0003236387 \t Training Accuracy: 36.70 \tValidation Loss: 0.0825087723 \tValidation Accuracy 42.63\n",
      "Validation loss decreased (0.0826842008 --> 0.0825087723).\n",
      "Epoch: 55 \tTraining Loss: 0.0003232796 \t Training Accuracy: 36.88 \tValidation Loss: 0.0823389366 \tValidation Accuracy 42.78\n",
      "Validation loss decreased (0.0825087723 --> 0.0823389366).\n",
      "Epoch: 56 \tTraining Loss: 0.0003226517 \t Training Accuracy: 36.97 \tValidation Loss: 0.0821778565 \tValidation Accuracy 42.94\n",
      "Validation loss decreased (0.0823389366 --> 0.0821778565).\n",
      "Epoch: 57 \tTraining Loss: 0.0003219630 \t Training Accuracy: 37.21 \tValidation Loss: 0.0820167920 \tValidation Accuracy 43.08\n",
      "Validation loss decreased (0.0821778565 --> 0.0820167920).\n",
      "Epoch: 58 \tTraining Loss: 0.0003213723 \t Training Accuracy: 37.19 \tValidation Loss: 0.0818662598 \tValidation Accuracy 43.23\n",
      "Validation loss decreased (0.0820167920 --> 0.0818662598).\n",
      "Epoch: 59 \tTraining Loss: 0.0003208309 \t Training Accuracy: 37.37 \tValidation Loss: 0.0817101004 \tValidation Accuracy 43.37\n",
      "Validation loss decreased (0.0818662598 --> 0.0817101004).\n",
      "Epoch: 60 \tTraining Loss: 0.0003205332 \t Training Accuracy: 37.45 \tValidation Loss: 0.0815711229 \tValidation Accuracy 43.53\n",
      "Validation loss decreased (0.0817101004 --> 0.0815711229).\n",
      "Epoch: 61 \tTraining Loss: 0.0003196295 \t Training Accuracy: 37.68 \tValidation Loss: 0.0814288424 \tValidation Accuracy 43.65\n",
      "Validation loss decreased (0.0815711229 --> 0.0814288424).\n",
      "Epoch: 62 \tTraining Loss: 0.0003193162 \t Training Accuracy: 37.77 \tValidation Loss: 0.0812879234 \tValidation Accuracy 43.79\n",
      "Validation loss decreased (0.0814288424 --> 0.0812879234).\n",
      "Epoch: 63 \tTraining Loss: 0.0003188463 \t Training Accuracy: 37.94 \tValidation Loss: 0.0811584587 \tValidation Accuracy 43.93\n",
      "Validation loss decreased (0.0812879234 --> 0.0811584587).\n",
      "Epoch: 64 \tTraining Loss: 0.0003179940 \t Training Accuracy: 38.01 \tValidation Loss: 0.0810259547 \tValidation Accuracy 44.06\n",
      "Validation loss decreased (0.0811584587 --> 0.0810259547).\n",
      "Epoch: 65 \tTraining Loss: 0.0003175943 \t Training Accuracy: 38.18 \tValidation Loss: 0.0808959044 \tValidation Accuracy 44.18\n",
      "Validation loss decreased (0.0810259547 --> 0.0808959044).\n",
      "Epoch: 66 \tTraining Loss: 0.0003174756 \t Training Accuracy: 38.12 \tValidation Loss: 0.0807685082 \tValidation Accuracy 44.29\n",
      "Validation loss decreased (0.0808959044 --> 0.0807685082).\n",
      "Epoch: 67 \tTraining Loss: 0.0003167043 \t Training Accuracy: 38.35 \tValidation Loss: 0.0806456574 \tValidation Accuracy 44.42\n",
      "Validation loss decreased (0.0807685082 --> 0.0806456574).\n",
      "Epoch: 68 \tTraining Loss: 0.0003165424 \t Training Accuracy: 38.40 \tValidation Loss: 0.0805268760 \tValidation Accuracy 44.54\n",
      "Validation loss decreased (0.0806456574 --> 0.0805268760).\n",
      "Epoch: 69 \tTraining Loss: 0.0003160151 \t Training Accuracy: 38.59 \tValidation Loss: 0.0804121905 \tValidation Accuracy 44.67\n",
      "Validation loss decreased (0.0805268760 --> 0.0804121905).\n",
      "Epoch: 70 \tTraining Loss: 0.0003155339 \t Training Accuracy: 38.63 \tValidation Loss: 0.0802999820 \tValidation Accuracy 44.81\n",
      "Validation loss decreased (0.0804121905 --> 0.0802999820).\n",
      "Epoch: 71 \tTraining Loss: 0.0003151045 \t Training Accuracy: 38.74 \tValidation Loss: 0.0801906858 \tValidation Accuracy 44.91\n",
      "Validation loss decreased (0.0802999820 --> 0.0801906858).\n",
      "Epoch: 72 \tTraining Loss: 0.0003147636 \t Training Accuracy: 38.78 \tValidation Loss: 0.0800835864 \tValidation Accuracy 45.02\n",
      "Validation loss decreased (0.0801906858 --> 0.0800835864).\n",
      "Epoch: 73 \tTraining Loss: 0.0003140481 \t Training Accuracy: 38.89 \tValidation Loss: 0.0799747908 \tValidation Accuracy 45.10\n",
      "Validation loss decreased (0.0800835864 --> 0.0799747908).\n",
      "Epoch: 74 \tTraining Loss: 0.0003139626 \t Training Accuracy: 38.96 \tValidation Loss: 0.0798758219 \tValidation Accuracy 45.24\n",
      "Validation loss decreased (0.0799747908 --> 0.0798758219).\n",
      "Epoch: 75 \tTraining Loss: 0.0003133847 \t Training Accuracy: 39.16 \tValidation Loss: 0.0797729283 \tValidation Accuracy 45.33\n",
      "Validation loss decreased (0.0798758219 --> 0.0797729283).\n",
      "Epoch: 76 \tTraining Loss: 0.0003132255 \t Training Accuracy: 39.18 \tValidation Loss: 0.0796761102 \tValidation Accuracy 45.42\n",
      "Validation loss decreased (0.0797729283 --> 0.0796761102).\n",
      "Epoch: 77 \tTraining Loss: 0.0003126817 \t Training Accuracy: 39.34 \tValidation Loss: 0.0795734750 \tValidation Accuracy 45.49\n",
      "Validation loss decreased (0.0796761102 --> 0.0795734750).\n",
      "Epoch: 78 \tTraining Loss: 0.0003126280 \t Training Accuracy: 39.32 \tValidation Loss: 0.0794715380 \tValidation Accuracy 45.58\n",
      "Validation loss decreased (0.0795734750 --> 0.0794715380).\n",
      "Epoch: 79 \tTraining Loss: 0.0003121592 \t Training Accuracy: 39.47 \tValidation Loss: 0.0793783961 \tValidation Accuracy 45.66\n",
      "Validation loss decreased (0.0794715380 --> 0.0793783961).\n",
      "Epoch: 80 \tTraining Loss: 0.0003117849 \t Training Accuracy: 39.59 \tValidation Loss: 0.0792930174 \tValidation Accuracy 45.76\n",
      "Validation loss decreased (0.0793783961 --> 0.0792930174).\n",
      "Epoch: 81 \tTraining Loss: 0.0003114313 \t Training Accuracy: 39.74 \tValidation Loss: 0.0792057833 \tValidation Accuracy 45.84\n",
      "Validation loss decreased (0.0792930174 --> 0.0792057833).\n",
      "Epoch: 82 \tTraining Loss: 0.0003110720 \t Training Accuracy: 39.66 \tValidation Loss: 0.0791182519 \tValidation Accuracy 45.93\n",
      "Validation loss decreased (0.0792057833 --> 0.0791182519).\n",
      "Epoch: 83 \tTraining Loss: 0.0003107531 \t Training Accuracy: 39.72 \tValidation Loss: 0.0790363376 \tValidation Accuracy 46.02\n",
      "Validation loss decreased (0.0791182519 --> 0.0790363376).\n",
      "Epoch: 84 \tTraining Loss: 0.0003102346 \t Training Accuracy: 39.93 \tValidation Loss: 0.0789480057 \tValidation Accuracy 46.09\n",
      "Validation loss decreased (0.0790363376 --> 0.0789480057).\n",
      "Epoch: 85 \tTraining Loss: 0.0003100697 \t Training Accuracy: 39.95 \tValidation Loss: 0.0788593821 \tValidation Accuracy 46.15\n",
      "Validation loss decreased (0.0789480057 --> 0.0788593821).\n",
      "Epoch: 86 \tTraining Loss: 0.0003098614 \t Training Accuracy: 39.92 \tValidation Loss: 0.0787830720 \tValidation Accuracy 46.24\n",
      "Validation loss decreased (0.0788593821 --> 0.0787830720).\n",
      "Epoch: 87 \tTraining Loss: 0.0003094498 \t Training Accuracy: 40.06 \tValidation Loss: 0.0787075508 \tValidation Accuracy 46.30\n",
      "Validation loss decreased (0.0787830720 --> 0.0787075508).\n",
      "Epoch: 88 \tTraining Loss: 0.0003090130 \t Training Accuracy: 40.09 \tValidation Loss: 0.0786246187 \tValidation Accuracy 46.39\n",
      "Validation loss decreased (0.0787075508 --> 0.0786246187).\n",
      "Epoch: 89 \tTraining Loss: 0.0003087971 \t Training Accuracy: 40.23 \tValidation Loss: 0.0785528515 \tValidation Accuracy 46.47\n",
      "Validation loss decreased (0.0786246187 --> 0.0785528515).\n",
      "Epoch: 90 \tTraining Loss: 0.0003087358 \t Training Accuracy: 40.25 \tValidation Loss: 0.0784727939 \tValidation Accuracy 46.52\n",
      "Validation loss decreased (0.0785528515 --> 0.0784727939).\n",
      "Epoch: 91 \tTraining Loss: 0.0003084019 \t Training Accuracy: 40.29 \tValidation Loss: 0.0783978849 \tValidation Accuracy 46.58\n",
      "Validation loss decreased (0.0784727939 --> 0.0783978849).\n",
      "Epoch: 92 \tTraining Loss: 0.0003080023 \t Training Accuracy: 40.39 \tValidation Loss: 0.0783317767 \tValidation Accuracy 46.66\n",
      "Validation loss decreased (0.0783978849 --> 0.0783317767).\n",
      "Epoch: 93 \tTraining Loss: 0.0003079260 \t Training Accuracy: 40.43 \tValidation Loss: 0.0782556565 \tValidation Accuracy 46.69\n",
      "Validation loss decreased (0.0783317767 --> 0.0782556565).\n",
      "Epoch: 94 \tTraining Loss: 0.0003074888 \t Training Accuracy: 40.48 \tValidation Loss: 0.0781901623 \tValidation Accuracy 46.75\n",
      "Validation loss decreased (0.0782556565 --> 0.0781901623).\n",
      "Epoch: 95 \tTraining Loss: 0.0003071479 \t Training Accuracy: 40.61 \tValidation Loss: 0.0781224505 \tValidation Accuracy 46.83\n",
      "Validation loss decreased (0.0781901623 --> 0.0781224505).\n",
      "Epoch: 96 \tTraining Loss: 0.0003071832 \t Training Accuracy: 40.57 \tValidation Loss: 0.0780567099 \tValidation Accuracy 46.90\n",
      "Validation loss decreased (0.0781224505 --> 0.0780567099).\n",
      "Epoch: 97 \tTraining Loss: 0.0003069079 \t Training Accuracy: 40.70 \tValidation Loss: 0.0779914804 \tValidation Accuracy 46.97\n",
      "Validation loss decreased (0.0780567099 --> 0.0779914804).\n",
      "Epoch: 98 \tTraining Loss: 0.0003063151 \t Training Accuracy: 40.80 \tValidation Loss: 0.0779174166 \tValidation Accuracy 47.04\n",
      "Validation loss decreased (0.0779914804 --> 0.0779174166).\n",
      "Epoch: 99 \tTraining Loss: 0.0003064336 \t Training Accuracy: 40.72 \tValidation Loss: 0.0778540413 \tValidation Accuracy 47.10\n",
      "Validation loss decreased (0.0779174166 --> 0.0778540413).\n",
      "Epoch: 100 \tTraining Loss: 0.0003059780 \t Training Accuracy: 40.83 \tValidation Loss: 0.0777946139 \tValidation Accuracy 47.16\n",
      "Validation loss decreased (0.0778540413 --> 0.0777946139).\n",
      "Epoch: 101 \tTraining Loss: 0.0003059744 \t Training Accuracy: 40.85 \tValidation Loss: 0.0777297503 \tValidation Accuracy 47.22\n",
      "Validation loss decreased (0.0777946139 --> 0.0777297503).\n",
      "Epoch: 102 \tTraining Loss: 0.0003053568 \t Training Accuracy: 40.94 \tValidation Loss: 0.0776691479 \tValidation Accuracy 47.27\n",
      "Validation loss decreased (0.0777297503 --> 0.0776691479).\n",
      "Epoch: 103 \tTraining Loss: 0.0003055169 \t Training Accuracy: 40.96 \tValidation Loss: 0.0775974707 \tValidation Accuracy 47.31\n",
      "Validation loss decreased (0.0776691479 --> 0.0775974707).\n",
      "Epoch: 104 \tTraining Loss: 0.0003049398 \t Training Accuracy: 41.16 \tValidation Loss: 0.0775349974 \tValidation Accuracy 47.39\n",
      "Validation loss decreased (0.0775974707 --> 0.0775349974).\n",
      "Epoch: 105 \tTraining Loss: 0.0003048846 \t Training Accuracy: 41.01 \tValidation Loss: 0.0774780127 \tValidation Accuracy 47.43\n",
      "Validation loss decreased (0.0775349974 --> 0.0774780127).\n",
      "Epoch: 106 \tTraining Loss: 0.0003047090 \t Training Accuracy: 41.15 \tValidation Loss: 0.0774316399 \tValidation Accuracy 47.52\n",
      "Validation loss decreased (0.0774780127 --> 0.0774316399).\n",
      "Epoch: 107 \tTraining Loss: 0.0003045629 \t Training Accuracy: 41.14 \tValidation Loss: 0.0773696101 \tValidation Accuracy 47.54\n",
      "Validation loss decreased (0.0774316399 --> 0.0773696101).\n",
      "Epoch: 108 \tTraining Loss: 0.0003043653 \t Training Accuracy: 41.21 \tValidation Loss: 0.0773106067 \tValidation Accuracy 47.60\n",
      "Validation loss decreased (0.0773696101 --> 0.0773106067).\n",
      "Epoch: 109 \tTraining Loss: 0.0003037180 \t Training Accuracy: 41.31 \tValidation Loss: 0.0772485435 \tValidation Accuracy 47.62\n",
      "Validation loss decreased (0.0773106067 --> 0.0772485435).\n",
      "Epoch: 110 \tTraining Loss: 0.0003039211 \t Training Accuracy: 41.33 \tValidation Loss: 0.0771962843 \tValidation Accuracy 47.68\n",
      "Validation loss decreased (0.0772485435 --> 0.0771962843).\n",
      "Epoch: 111 \tTraining Loss: 0.0003035145 \t Training Accuracy: 41.37 \tValidation Loss: 0.0771419863 \tValidation Accuracy 47.73\n",
      "Validation loss decreased (0.0771962843 --> 0.0771419863).\n",
      "Epoch: 112 \tTraining Loss: 0.0003030990 \t Training Accuracy: 41.39 \tValidation Loss: 0.0770895612 \tValidation Accuracy 47.77\n",
      "Validation loss decreased (0.0771419863 --> 0.0770895612).\n",
      "Epoch: 113 \tTraining Loss: 0.0003029691 \t Training Accuracy: 41.50 \tValidation Loss: 0.0770324461 \tValidation Accuracy 47.81\n",
      "Validation loss decreased (0.0770895612 --> 0.0770324461).\n",
      "Epoch: 114 \tTraining Loss: 0.0003027864 \t Training Accuracy: 41.53 \tValidation Loss: 0.0769806183 \tValidation Accuracy 47.85\n",
      "Validation loss decreased (0.0770324461 --> 0.0769806183).\n",
      "Epoch: 115 \tTraining Loss: 0.0003025968 \t Training Accuracy: 41.58 \tValidation Loss: 0.0769300854 \tValidation Accuracy 47.90\n",
      "Validation loss decreased (0.0769806183 --> 0.0769300854).\n",
      "Epoch: 116 \tTraining Loss: 0.0003025194 \t Training Accuracy: 41.57 \tValidation Loss: 0.0768809967 \tValidation Accuracy 47.95\n",
      "Validation loss decreased (0.0769300854 --> 0.0768809967).\n",
      "Epoch: 117 \tTraining Loss: 0.0003024371 \t Training Accuracy: 41.66 \tValidation Loss: 0.0768325180 \tValidation Accuracy 48.01\n",
      "Validation loss decreased (0.0768809967 --> 0.0768325180).\n",
      "Epoch: 118 \tTraining Loss: 0.0003021604 \t Training Accuracy: 41.69 \tValidation Loss: 0.0767802587 \tValidation Accuracy 48.05\n",
      "Validation loss decreased (0.0768325180 --> 0.0767802587).\n",
      "Epoch: 119 \tTraining Loss: 0.0003022590 \t Training Accuracy: 41.65 \tValidation Loss: 0.0767394704 \tValidation Accuracy 48.11\n",
      "Validation loss decreased (0.0767802587 --> 0.0767394704).\n",
      "Epoch: 120 \tTraining Loss: 0.0003019731 \t Training Accuracy: 41.74 \tValidation Loss: 0.0766957867 \tValidation Accuracy 48.17\n",
      "Validation loss decreased (0.0767394704 --> 0.0766957867).\n",
      "Epoch: 121 \tTraining Loss: 0.0003015345 \t Training Accuracy: 41.81 \tValidation Loss: 0.0766518937 \tValidation Accuracy 48.20\n",
      "Validation loss decreased (0.0766957867 --> 0.0766518937).\n",
      "Epoch: 122 \tTraining Loss: 0.0003013296 \t Training Accuracy: 41.82 \tValidation Loss: 0.0766056323 \tValidation Accuracy 48.26\n",
      "Validation loss decreased (0.0766518937 --> 0.0766056323).\n",
      "Epoch: 123 \tTraining Loss: 0.0003010904 \t Training Accuracy: 41.91 \tValidation Loss: 0.0765579821 \tValidation Accuracy 48.30\n",
      "Validation loss decreased (0.0766056323 --> 0.0765579821).\n",
      "Epoch: 124 \tTraining Loss: 0.0003009231 \t Training Accuracy: 42.03 \tValidation Loss: 0.0765019681 \tValidation Accuracy 48.31\n",
      "Validation loss decreased (0.0765579821 --> 0.0765019681).\n",
      "Epoch: 125 \tTraining Loss: 0.0003007415 \t Training Accuracy: 42.03 \tValidation Loss: 0.0764573553 \tValidation Accuracy 48.38\n",
      "Validation loss decreased (0.0765019681 --> 0.0764573553).\n",
      "Epoch: 126 \tTraining Loss: 0.0003009357 \t Training Accuracy: 42.04 \tValidation Loss: 0.0764134543 \tValidation Accuracy 48.41\n",
      "Validation loss decreased (0.0764573553 --> 0.0764134543).\n",
      "Epoch: 127 \tTraining Loss: 0.0003004926 \t Training Accuracy: 41.99 \tValidation Loss: 0.0763650904 \tValidation Accuracy 48.45\n",
      "Validation loss decreased (0.0764134543 --> 0.0763650904).\n",
      "Epoch: 128 \tTraining Loss: 0.0003004731 \t Training Accuracy: 42.10 \tValidation Loss: 0.0763259970 \tValidation Accuracy 48.50\n",
      "Validation loss decreased (0.0763650904 --> 0.0763259970).\n",
      "Epoch: 129 \tTraining Loss: 0.0003003085 \t Training Accuracy: 42.15 \tValidation Loss: 0.0762894789 \tValidation Accuracy 48.56\n",
      "Validation loss decreased (0.0763259970 --> 0.0762894789).\n",
      "Epoch: 130 \tTraining Loss: 0.0003000433 \t Training Accuracy: 42.13 \tValidation Loss: 0.0762369905 \tValidation Accuracy 48.58\n",
      "Validation loss decreased (0.0762894789 --> 0.0762369905).\n",
      "Epoch: 131 \tTraining Loss: 0.0002998587 \t Training Accuracy: 42.19 \tValidation Loss: 0.0761902714 \tValidation Accuracy 48.61\n",
      "Validation loss decreased (0.0762369905 --> 0.0761902714).\n",
      "Epoch: 132 \tTraining Loss: 0.0002998193 \t Training Accuracy: 42.03 \tValidation Loss: 0.0761583213 \tValidation Accuracy 48.67\n",
      "Validation loss decreased (0.0761902714 --> 0.0761583213).\n",
      "Epoch: 133 \tTraining Loss: 0.0002994136 \t Training Accuracy: 42.20 \tValidation Loss: 0.0761239500 \tValidation Accuracy 48.71\n",
      "Validation loss decreased (0.0761583213 --> 0.0761239500).\n",
      "Epoch: 134 \tTraining Loss: 0.0002993849 \t Training Accuracy: 42.40 \tValidation Loss: 0.0760822202 \tValidation Accuracy 48.73\n",
      "Validation loss decreased (0.0761239500 --> 0.0760822202).\n",
      "Epoch: 135 \tTraining Loss: 0.0002992918 \t Training Accuracy: 42.30 \tValidation Loss: 0.0760461449 \tValidation Accuracy 48.76\n",
      "Validation loss decreased (0.0760822202 --> 0.0760461449).\n",
      "Epoch: 136 \tTraining Loss: 0.0002992562 \t Training Accuracy: 42.40 \tValidation Loss: 0.0759989062 \tValidation Accuracy 48.79\n",
      "Validation loss decreased (0.0760461449 --> 0.0759989062).\n",
      "Epoch: 137 \tTraining Loss: 0.0002992399 \t Training Accuracy: 42.40 \tValidation Loss: 0.0759590929 \tValidation Accuracy 48.82\n",
      "Validation loss decreased (0.0759989062 --> 0.0759590929).\n",
      "Epoch: 138 \tTraining Loss: 0.0002987744 \t Training Accuracy: 42.40 \tValidation Loss: 0.0759185149 \tValidation Accuracy 48.85\n",
      "Validation loss decreased (0.0759590929 --> 0.0759185149).\n",
      "Epoch: 139 \tTraining Loss: 0.0002987300 \t Training Accuracy: 42.44 \tValidation Loss: 0.0758865677 \tValidation Accuracy 48.89\n",
      "Validation loss decreased (0.0759185149 --> 0.0758865677).\n",
      "Epoch: 140 \tTraining Loss: 0.0002986581 \t Training Accuracy: 42.53 \tValidation Loss: 0.0758465327 \tValidation Accuracy 48.91\n",
      "Validation loss decreased (0.0758865677 --> 0.0758465327).\n",
      "Epoch: 141 \tTraining Loss: 0.0002983232 \t Training Accuracy: 42.49 \tValidation Loss: 0.0758089146 \tValidation Accuracy 48.95\n",
      "Validation loss decreased (0.0758465327 --> 0.0758089146).\n",
      "Epoch: 142 \tTraining Loss: 0.0002983353 \t Training Accuracy: 42.60 \tValidation Loss: 0.0757648734 \tValidation Accuracy 48.96\n",
      "Validation loss decreased (0.0758089146 --> 0.0757648734).\n",
      "Epoch: 143 \tTraining Loss: 0.0002979677 \t Training Accuracy: 42.61 \tValidation Loss: 0.0757292050 \tValidation Accuracy 49.00\n",
      "Validation loss decreased (0.0757648734 --> 0.0757292050).\n",
      "Epoch: 144 \tTraining Loss: 0.0002978373 \t Training Accuracy: 42.54 \tValidation Loss: 0.0756912975 \tValidation Accuracy 49.03\n",
      "Validation loss decreased (0.0757292050 --> 0.0756912975).\n",
      "Epoch: 145 \tTraining Loss: 0.0002978004 \t Training Accuracy: 42.69 \tValidation Loss: 0.0756579338 \tValidation Accuracy 49.07\n",
      "Validation loss decreased (0.0756912975 --> 0.0756579338).\n",
      "Epoch: 146 \tTraining Loss: 0.0002973250 \t Training Accuracy: 42.76 \tValidation Loss: 0.0756150723 \tValidation Accuracy 49.08\n",
      "Validation loss decreased (0.0756579338 --> 0.0756150723).\n",
      "Epoch: 147 \tTraining Loss: 0.0002977424 \t Training Accuracy: 42.64 \tValidation Loss: 0.0755840619 \tValidation Accuracy 49.13\n",
      "Validation loss decreased (0.0756150723 --> 0.0755840619).\n",
      "Epoch: 148 \tTraining Loss: 0.0002973485 \t Training Accuracy: 42.72 \tValidation Loss: 0.0755536478 \tValidation Accuracy 49.16\n",
      "Validation loss decreased (0.0755840619 --> 0.0755536478).\n",
      "Epoch: 149 \tTraining Loss: 0.0002971468 \t Training Accuracy: 42.73 \tValidation Loss: 0.0755093486 \tValidation Accuracy 49.17\n",
      "Validation loss decreased (0.0755536478 --> 0.0755093486).\n",
      "Epoch: 150 \tTraining Loss: 0.0002969795 \t Training Accuracy: 42.76 \tValidation Loss: 0.0754775048 \tValidation Accuracy 49.21\n",
      "Validation loss decreased (0.0755093486 --> 0.0754775048).\n",
      "Epoch: 151 \tTraining Loss: 0.0002970433 \t Training Accuracy: 42.72 \tValidation Loss: 0.0754421048 \tValidation Accuracy 49.23\n",
      "Validation loss decreased (0.0754775048 --> 0.0754421048).\n",
      "Epoch: 152 \tTraining Loss: 0.0002969446 \t Training Accuracy: 42.72 \tValidation Loss: 0.0754121880 \tValidation Accuracy 49.27\n",
      "Validation loss decreased (0.0754421048 --> 0.0754121880).\n",
      "Epoch: 153 \tTraining Loss: 0.0002965374 \t Training Accuracy: 42.87 \tValidation Loss: 0.0753816191 \tValidation Accuracy 49.32\n",
      "Validation loss decreased (0.0754121880 --> 0.0753816191).\n",
      "Epoch: 154 \tTraining Loss: 0.0002965718 \t Training Accuracy: 42.86 \tValidation Loss: 0.0753491345 \tValidation Accuracy 49.36\n",
      "Validation loss decreased (0.0753816191 --> 0.0753491345).\n",
      "Epoch: 155 \tTraining Loss: 0.0002964462 \t Training Accuracy: 42.80 \tValidation Loss: 0.0753214480 \tValidation Accuracy 49.40\n",
      "Validation loss decreased (0.0753491345 --> 0.0753214480).\n",
      "Epoch: 156 \tTraining Loss: 0.0002964295 \t Training Accuracy: 42.90 \tValidation Loss: 0.0752845866 \tValidation Accuracy 49.43\n",
      "Validation loss decreased (0.0753214480 --> 0.0752845866).\n",
      "Epoch: 157 \tTraining Loss: 0.0002963206 \t Training Accuracy: 42.93 \tValidation Loss: 0.0752514076 \tValidation Accuracy 49.46\n",
      "Validation loss decreased (0.0752845866 --> 0.0752514076).\n",
      "Epoch: 158 \tTraining Loss: 0.0002960412 \t Training Accuracy: 42.98 \tValidation Loss: 0.0752259377 \tValidation Accuracy 49.49\n",
      "Validation loss decreased (0.0752514076 --> 0.0752259377).\n",
      "Epoch: 159 \tTraining Loss: 0.0002962050 \t Training Accuracy: 43.07 \tValidation Loss: 0.0751952426 \tValidation Accuracy 49.50\n",
      "Validation loss decreased (0.0752259377 --> 0.0751952426).\n",
      "Epoch: 160 \tTraining Loss: 0.0002957774 \t Training Accuracy: 43.04 \tValidation Loss: 0.0751635462 \tValidation Accuracy 49.52\n",
      "Validation loss decreased (0.0751952426 --> 0.0751635462).\n",
      "Epoch: 161 \tTraining Loss: 0.0002956904 \t Training Accuracy: 43.05 \tValidation Loss: 0.0751308277 \tValidation Accuracy 49.56\n",
      "Validation loss decreased (0.0751635462 --> 0.0751308277).\n",
      "Epoch: 162 \tTraining Loss: 0.0002954246 \t Training Accuracy: 43.02 \tValidation Loss: 0.0751005800 \tValidation Accuracy 49.59\n",
      "Validation loss decreased (0.0751308277 --> 0.0751005800).\n",
      "Epoch: 163 \tTraining Loss: 0.0002954706 \t Training Accuracy: 43.19 \tValidation Loss: 0.0750710828 \tValidation Accuracy 49.61\n",
      "Validation loss decreased (0.0751005800 --> 0.0750710828).\n",
      "Epoch: 164 \tTraining Loss: 0.0002953289 \t Training Accuracy: 43.05 \tValidation Loss: 0.0750445053 \tValidation Accuracy 49.64\n",
      "Validation loss decreased (0.0750710828 --> 0.0750445053).\n",
      "Epoch: 165 \tTraining Loss: 0.0002953392 \t Training Accuracy: 43.12 \tValidation Loss: 0.0750161468 \tValidation Accuracy 49.66\n",
      "Validation loss decreased (0.0750445053 --> 0.0750161468).\n",
      "Epoch: 166 \tTraining Loss: 0.0002951085 \t Training Accuracy: 43.18 \tValidation Loss: 0.0749853629 \tValidation Accuracy 49.68\n",
      "Validation loss decreased (0.0750161468 --> 0.0749853629).\n",
      "Epoch: 167 \tTraining Loss: 0.0002950702 \t Training Accuracy: 43.24 \tValidation Loss: 0.0749567184 \tValidation Accuracy 49.71\n",
      "Validation loss decreased (0.0749853629 --> 0.0749567184).\n",
      "Epoch: 168 \tTraining Loss: 0.0002949052 \t Training Accuracy: 43.26 \tValidation Loss: 0.0749303460 \tValidation Accuracy 49.74\n",
      "Validation loss decreased (0.0749567184 --> 0.0749303460).\n",
      "Epoch: 169 \tTraining Loss: 0.0002947458 \t Training Accuracy: 43.28 \tValidation Loss: 0.0749016341 \tValidation Accuracy 49.75\n",
      "Validation loss decreased (0.0749303460 --> 0.0749016341).\n",
      "Epoch: 170 \tTraining Loss: 0.0002943989 \t Training Accuracy: 43.23 \tValidation Loss: 0.0748770300 \tValidation Accuracy 49.79\n",
      "Validation loss decreased (0.0749016341 --> 0.0748770300).\n",
      "Epoch: 171 \tTraining Loss: 0.0002945037 \t Training Accuracy: 43.43 \tValidation Loss: 0.0748441952 \tValidation Accuracy 49.81\n",
      "Validation loss decreased (0.0748770300 --> 0.0748441952).\n",
      "Epoch: 172 \tTraining Loss: 0.0002949014 \t Training Accuracy: 43.32 \tValidation Loss: 0.0748134438 \tValidation Accuracy 49.82\n",
      "Validation loss decreased (0.0748441952 --> 0.0748134438).\n",
      "Epoch: 173 \tTraining Loss: 0.0002944160 \t Training Accuracy: 43.31 \tValidation Loss: 0.0747883674 \tValidation Accuracy 49.86\n",
      "Validation loss decreased (0.0748134438 --> 0.0747883674).\n",
      "Epoch: 174 \tTraining Loss: 0.0002943949 \t Training Accuracy: 43.35 \tValidation Loss: 0.0747595426 \tValidation Accuracy 49.87\n",
      "Validation loss decreased (0.0747883674 --> 0.0747595426).\n",
      "Epoch: 175 \tTraining Loss: 0.0002940082 \t Training Accuracy: 43.35 \tValidation Loss: 0.0747315254 \tValidation Accuracy 49.88\n",
      "Validation loss decreased (0.0747595426 --> 0.0747315254).\n",
      "Epoch: 176 \tTraining Loss: 0.0002941658 \t Training Accuracy: 43.32 \tValidation Loss: 0.0747094121 \tValidation Accuracy 49.92\n",
      "Validation loss decreased (0.0747315254 --> 0.0747094121).\n",
      "Epoch: 177 \tTraining Loss: 0.0002937593 \t Training Accuracy: 43.51 \tValidation Loss: 0.0746843366 \tValidation Accuracy 49.94\n",
      "Validation loss decreased (0.0747094121 --> 0.0746843366).\n",
      "Epoch: 178 \tTraining Loss: 0.0002936949 \t Training Accuracy: 43.47 \tValidation Loss: 0.0746542450 \tValidation Accuracy 49.96\n",
      "Validation loss decreased (0.0746843366 --> 0.0746542450).\n",
      "Epoch: 179 \tTraining Loss: 0.0002938737 \t Training Accuracy: 43.43 \tValidation Loss: 0.0746332093 \tValidation Accuracy 50.00\n",
      "Validation loss decreased (0.0746542450 --> 0.0746332093).\n",
      "Epoch: 180 \tTraining Loss: 0.0002939137 \t Training Accuracy: 43.45 \tValidation Loss: 0.0746038697 \tValidation Accuracy 50.01\n",
      "Validation loss decreased (0.0746332093 --> 0.0746038697).\n",
      "Epoch: 181 \tTraining Loss: 0.0002934806 \t Training Accuracy: 43.59 \tValidation Loss: 0.0745784721 \tValidation Accuracy 50.03\n",
      "Validation loss decreased (0.0746038697 --> 0.0745784721).\n",
      "Epoch: 182 \tTraining Loss: 0.0002936737 \t Training Accuracy: 43.53 \tValidation Loss: 0.0745424269 \tValidation Accuracy 50.02\n",
      "Validation loss decreased (0.0745784721 --> 0.0745424269).\n",
      "Epoch: 183 \tTraining Loss: 0.0002933865 \t Training Accuracy: 43.54 \tValidation Loss: 0.0745225201 \tValidation Accuracy 50.07\n",
      "Validation loss decreased (0.0745424269 --> 0.0745225201).\n",
      "Epoch: 184 \tTraining Loss: 0.0002933306 \t Training Accuracy: 43.53 \tValidation Loss: 0.0745033174 \tValidation Accuracy 50.10\n",
      "Validation loss decreased (0.0745225201 --> 0.0745033174).\n",
      "Epoch: 185 \tTraining Loss: 0.0002930564 \t Training Accuracy: 43.49 \tValidation Loss: 0.0744809703 \tValidation Accuracy 50.14\n",
      "Validation loss decreased (0.0745033174 --> 0.0744809703).\n",
      "Epoch: 186 \tTraining Loss: 0.0002931571 \t Training Accuracy: 43.50 \tValidation Loss: 0.0744576494 \tValidation Accuracy 50.16\n",
      "Validation loss decreased (0.0744809703 --> 0.0744576494).\n",
      "Epoch: 187 \tTraining Loss: 0.0002929710 \t Training Accuracy: 43.63 \tValidation Loss: 0.0744362816 \tValidation Accuracy 50.18\n",
      "Validation loss decreased (0.0744576494 --> 0.0744362816).\n",
      "Epoch: 188 \tTraining Loss: 0.0002928839 \t Training Accuracy: 43.63 \tValidation Loss: 0.0744067945 \tValidation Accuracy 50.18\n",
      "Validation loss decreased (0.0744362816 --> 0.0744067945).\n",
      "Epoch: 189 \tTraining Loss: 0.0002927660 \t Training Accuracy: 43.60 \tValidation Loss: 0.0743803906 \tValidation Accuracy 50.19\n",
      "Validation loss decreased (0.0744067945 --> 0.0743803906).\n",
      "Epoch: 190 \tTraining Loss: 0.0002927754 \t Training Accuracy: 43.65 \tValidation Loss: 0.0743597842 \tValidation Accuracy 50.21\n",
      "Validation loss decreased (0.0743803906 --> 0.0743597842).\n",
      "Epoch: 191 \tTraining Loss: 0.0002926533 \t Training Accuracy: 43.71 \tValidation Loss: 0.0743366121 \tValidation Accuracy 50.23\n",
      "Validation loss decreased (0.0743597842 --> 0.0743366121).\n",
      "Epoch: 192 \tTraining Loss: 0.0002923033 \t Training Accuracy: 43.63 \tValidation Loss: 0.0743160784 \tValidation Accuracy 50.27\n",
      "Validation loss decreased (0.0743366121 --> 0.0743160784).\n",
      "Epoch: 193 \tTraining Loss: 0.0002923956 \t Training Accuracy: 43.81 \tValidation Loss: 0.0742831432 \tValidation Accuracy 50.26\n",
      "Validation loss decreased (0.0743160784 --> 0.0742831432).\n",
      "Epoch: 194 \tTraining Loss: 0.0002923237 \t Training Accuracy: 43.73 \tValidation Loss: 0.0742624584 \tValidation Accuracy 50.29\n",
      "Validation loss decreased (0.0742831432 --> 0.0742624584).\n",
      "Epoch: 195 \tTraining Loss: 0.0002921736 \t Training Accuracy: 43.75 \tValidation Loss: 0.0742402026 \tValidation Accuracy 50.30\n",
      "Validation loss decreased (0.0742624584 --> 0.0742402026).\n",
      "Epoch: 196 \tTraining Loss: 0.0002921780 \t Training Accuracy: 43.79 \tValidation Loss: 0.0742040343 \tValidation Accuracy 50.30\n",
      "Validation loss decreased (0.0742402026 --> 0.0742040343).\n",
      "Epoch: 197 \tTraining Loss: 0.0002918937 \t Training Accuracy: 43.79 \tValidation Loss: 0.0741826287 \tValidation Accuracy 50.31\n",
      "Validation loss decreased (0.0742040343 --> 0.0741826287).\n",
      "Epoch: 198 \tTraining Loss: 0.0002921271 \t Training Accuracy: 43.75 \tValidation Loss: 0.0741689579 \tValidation Accuracy 50.35\n",
      "Validation loss decreased (0.0741826287 --> 0.0741689579).\n",
      "Epoch: 199 \tTraining Loss: 0.0002921728 \t Training Accuracy: 43.82 \tValidation Loss: 0.0741483351 \tValidation Accuracy 50.37\n",
      "Validation loss decreased (0.0741689579 --> 0.0741483351).\n",
      "Epoch: 200 \tTraining Loss: 0.0002914451 \t Training Accuracy: 43.85 \tValidation Loss: 0.0741210184 \tValidation Accuracy 50.37\n",
      "Validation loss decreased (0.0741483351 --> 0.0741210184).\n",
      "Epoch: 201 \tTraining Loss: 0.0002918271 \t Training Accuracy: 43.87 \tValidation Loss: 0.0740993855 \tValidation Accuracy 50.39\n",
      "Validation loss decreased (0.0741210184 --> 0.0740993855).\n",
      "Epoch: 202 \tTraining Loss: 0.0002917514 \t Training Accuracy: 43.78 \tValidation Loss: 0.0740830549 \tValidation Accuracy 50.43\n",
      "Validation loss decreased (0.0740993855 --> 0.0740830549).\n",
      "Epoch: 203 \tTraining Loss: 0.0002915961 \t Training Accuracy: 43.94 \tValidation Loss: 0.0740626746 \tValidation Accuracy 50.45\n",
      "Validation loss decreased (0.0740830549 --> 0.0740626746).\n",
      "Epoch: 204 \tTraining Loss: 0.0002912850 \t Training Accuracy: 43.95 \tValidation Loss: 0.0740473186 \tValidation Accuracy 50.51\n",
      "Validation loss decreased (0.0740626746 --> 0.0740473186).\n",
      "Epoch: 205 \tTraining Loss: 0.0002913186 \t Training Accuracy: 43.96 \tValidation Loss: 0.0740176451 \tValidation Accuracy 50.49\n",
      "Validation loss decreased (0.0740473186 --> 0.0740176451).\n",
      "Epoch: 206 \tTraining Loss: 0.0002912750 \t Training Accuracy: 43.91 \tValidation Loss: 0.0739945783 \tValidation Accuracy 50.52\n",
      "Validation loss decreased (0.0740176451 --> 0.0739945783).\n",
      "Epoch: 207 \tTraining Loss: 0.0002910504 \t Training Accuracy: 43.98 \tValidation Loss: 0.0739821948 \tValidation Accuracy 50.56\n",
      "Validation loss decreased (0.0739945783 --> 0.0739821948).\n",
      "Epoch: 208 \tTraining Loss: 0.0002909474 \t Training Accuracy: 43.96 \tValidation Loss: 0.0739578677 \tValidation Accuracy 50.57\n",
      "Validation loss decreased (0.0739821948 --> 0.0739578677).\n",
      "Epoch: 209 \tTraining Loss: 0.0002908851 \t Training Accuracy: 44.05 \tValidation Loss: 0.0739352738 \tValidation Accuracy 50.60\n",
      "Validation loss decreased (0.0739578677 --> 0.0739352738).\n",
      "Epoch: 210 \tTraining Loss: 0.0002909321 \t Training Accuracy: 43.97 \tValidation Loss: 0.0739119951 \tValidation Accuracy 50.59\n",
      "Validation loss decreased (0.0739352738 --> 0.0739119951).\n",
      "Epoch: 211 \tTraining Loss: 0.0002906960 \t Training Accuracy: 43.98 \tValidation Loss: 0.0738909064 \tValidation Accuracy 50.61\n",
      "Validation loss decreased (0.0739119951 --> 0.0738909064).\n",
      "Epoch: 212 \tTraining Loss: 0.0002907663 \t Training Accuracy: 44.05 \tValidation Loss: 0.0738761274 \tValidation Accuracy 50.63\n",
      "Validation loss decreased (0.0738909064 --> 0.0738761274).\n",
      "Epoch: 213 \tTraining Loss: 0.0002902993 \t Training Accuracy: 44.06 \tValidation Loss: 0.0738550782 \tValidation Accuracy 50.67\n",
      "Validation loss decreased (0.0738761274 --> 0.0738550782).\n",
      "Epoch: 214 \tTraining Loss: 0.0002904508 \t Training Accuracy: 44.10 \tValidation Loss: 0.0738277177 \tValidation Accuracy 50.65\n",
      "Validation loss decreased (0.0738550782 --> 0.0738277177).\n",
      "Epoch: 215 \tTraining Loss: 0.0002905298 \t Training Accuracy: 44.13 \tValidation Loss: 0.0738080199 \tValidation Accuracy 50.68\n",
      "Validation loss decreased (0.0738277177 --> 0.0738080199).\n",
      "Epoch: 216 \tTraining Loss: 0.0002905322 \t Training Accuracy: 44.10 \tValidation Loss: 0.0737902534 \tValidation Accuracy 50.69\n",
      "Validation loss decreased (0.0738080199 --> 0.0737902534).\n",
      "Epoch: 217 \tTraining Loss: 0.0002904116 \t Training Accuracy: 44.07 \tValidation Loss: 0.0737706450 \tValidation Accuracy 50.72\n",
      "Validation loss decreased (0.0737902534 --> 0.0737706450).\n",
      "Epoch: 218 \tTraining Loss: 0.0002901730 \t Training Accuracy: 44.12 \tValidation Loss: 0.0737587705 \tValidation Accuracy 50.77\n",
      "Validation loss decreased (0.0737706450 --> 0.0737587705).\n",
      "Epoch: 219 \tTraining Loss: 0.0002900857 \t Training Accuracy: 44.12 \tValidation Loss: 0.0737390944 \tValidation Accuracy 50.77\n",
      "Validation loss decreased (0.0737587705 --> 0.0737390944).\n",
      "Epoch: 220 \tTraining Loss: 0.0002903038 \t Training Accuracy: 44.21 \tValidation Loss: 0.0737173499 \tValidation Accuracy 50.79\n",
      "Validation loss decreased (0.0737390944 --> 0.0737173499).\n",
      "Epoch: 221 \tTraining Loss: 0.0002900403 \t Training Accuracy: 44.20 \tValidation Loss: 0.0736946879 \tValidation Accuracy 50.79\n",
      "Validation loss decreased (0.0737173499 --> 0.0736946879).\n",
      "Epoch: 222 \tTraining Loss: 0.0002895671 \t Training Accuracy: 44.23 \tValidation Loss: 0.0736775977 \tValidation Accuracy 50.79\n",
      "Validation loss decreased (0.0736946879 --> 0.0736775977).\n",
      "Epoch: 223 \tTraining Loss: 0.0002899161 \t Training Accuracy: 44.25 \tValidation Loss: 0.0736609846 \tValidation Accuracy 50.83\n",
      "Validation loss decreased (0.0736775977 --> 0.0736609846).\n",
      "Epoch: 224 \tTraining Loss: 0.0002896277 \t Training Accuracy: 44.24 \tValidation Loss: 0.0736380639 \tValidation Accuracy 50.84\n",
      "Validation loss decreased (0.0736609846 --> 0.0736380639).\n",
      "Epoch: 225 \tTraining Loss: 0.0002894780 \t Training Accuracy: 44.22 \tValidation Loss: 0.0736204011 \tValidation Accuracy 50.86\n",
      "Validation loss decreased (0.0736380639 --> 0.0736204011).\n",
      "Epoch: 226 \tTraining Loss: 0.0002894845 \t Training Accuracy: 44.31 \tValidation Loss: 0.0736037542 \tValidation Accuracy 50.89\n",
      "Validation loss decreased (0.0736204011 --> 0.0736037542).\n",
      "Epoch: 227 \tTraining Loss: 0.0002896552 \t Training Accuracy: 44.22 \tValidation Loss: 0.0735871801 \tValidation Accuracy 50.92\n",
      "Validation loss decreased (0.0736037542 --> 0.0735871801).\n",
      "Epoch: 228 \tTraining Loss: 0.0002894976 \t Training Accuracy: 44.27 \tValidation Loss: 0.0735656124 \tValidation Accuracy 50.92\n",
      "Validation loss decreased (0.0735871801 --> 0.0735656124).\n",
      "Epoch: 229 \tTraining Loss: 0.0002894412 \t Training Accuracy: 44.25 \tValidation Loss: 0.0735562094 \tValidation Accuracy 50.96\n",
      "Validation loss decreased (0.0735656124 --> 0.0735562094).\n",
      "Epoch: 230 \tTraining Loss: 0.0002889233 \t Training Accuracy: 44.42 \tValidation Loss: 0.0735292779 \tValidation Accuracy 50.96\n",
      "Validation loss decreased (0.0735562094 --> 0.0735292779).\n",
      "Epoch: 231 \tTraining Loss: 0.0002894432 \t Training Accuracy: 44.28 \tValidation Loss: 0.0735176667 \tValidation Accuracy 50.98\n",
      "Validation loss decreased (0.0735292779 --> 0.0735176667).\n",
      "Epoch: 232 \tTraining Loss: 0.0002891529 \t Training Accuracy: 44.30 \tValidation Loss: 0.0734953321 \tValidation Accuracy 50.97\n",
      "Validation loss decreased (0.0735176667 --> 0.0734953321).\n",
      "Epoch: 233 \tTraining Loss: 0.0002891815 \t Training Accuracy: 44.38 \tValidation Loss: 0.0734717849 \tValidation Accuracy 50.95\n",
      "Validation loss decreased (0.0734953321 --> 0.0734717849).\n",
      "Epoch: 234 \tTraining Loss: 0.0002887673 \t Training Accuracy: 44.38 \tValidation Loss: 0.0734533111 \tValidation Accuracy 50.98\n",
      "Validation loss decreased (0.0734717849 --> 0.0734533111).\n",
      "Epoch: 235 \tTraining Loss: 0.0002888957 \t Training Accuracy: 44.37 \tValidation Loss: 0.0734379076 \tValidation Accuracy 51.00\n",
      "Validation loss decreased (0.0734533111 --> 0.0734379076).\n",
      "Epoch: 236 \tTraining Loss: 0.0002890329 \t Training Accuracy: 44.43 \tValidation Loss: 0.0734225549 \tValidation Accuracy 51.01\n",
      "Validation loss decreased (0.0734379076 --> 0.0734225549).\n",
      "Epoch: 237 \tTraining Loss: 0.0002888608 \t Training Accuracy: 44.28 \tValidation Loss: 0.0734073008 \tValidation Accuracy 51.05\n",
      "Validation loss decreased (0.0734225549 --> 0.0734073008).\n",
      "Epoch: 238 \tTraining Loss: 0.0002886079 \t Training Accuracy: 44.45 \tValidation Loss: 0.0733902004 \tValidation Accuracy 51.05\n",
      "Validation loss decreased (0.0734073008 --> 0.0733902004).\n",
      "Epoch: 239 \tTraining Loss: 0.0002885628 \t Training Accuracy: 44.44 \tValidation Loss: 0.0733795894 \tValidation Accuracy 51.09\n",
      "Validation loss decreased (0.0733902004 --> 0.0733795894).\n",
      "Epoch: 240 \tTraining Loss: 0.0002886839 \t Training Accuracy: 44.43 \tValidation Loss: 0.0733595145 \tValidation Accuracy 51.09\n",
      "Validation loss decreased (0.0733795894 --> 0.0733595145).\n",
      "Epoch: 241 \tTraining Loss: 0.0002888495 \t Training Accuracy: 44.51 \tValidation Loss: 0.0733358192 \tValidation Accuracy 51.08\n",
      "Validation loss decreased (0.0733595145 --> 0.0733358192).\n",
      "Epoch: 242 \tTraining Loss: 0.0002885164 \t Training Accuracy: 44.41 \tValidation Loss: 0.0733210771 \tValidation Accuracy 51.10\n",
      "Validation loss decreased (0.0733358192 --> 0.0733210771).\n",
      "Epoch: 243 \tTraining Loss: 0.0002883305 \t Training Accuracy: 44.47 \tValidation Loss: 0.0733059723 \tValidation Accuracy 51.13\n",
      "Validation loss decreased (0.0733210771 --> 0.0733059723).\n",
      "Epoch: 244 \tTraining Loss: 0.0002881269 \t Training Accuracy: 44.53 \tValidation Loss: 0.0732863311 \tValidation Accuracy 51.12\n",
      "Validation loss decreased (0.0733059723 --> 0.0732863311).\n",
      "Epoch: 245 \tTraining Loss: 0.0002881370 \t Training Accuracy: 44.51 \tValidation Loss: 0.0732699624 \tValidation Accuracy 51.14\n",
      "Validation loss decreased (0.0732863311 --> 0.0732699624).\n",
      "Epoch: 246 \tTraining Loss: 0.0002880418 \t Training Accuracy: 44.55 \tValidation Loss: 0.0732455764 \tValidation Accuracy 51.13\n",
      "Validation loss decreased (0.0732699624 --> 0.0732455764).\n",
      "Epoch: 247 \tTraining Loss: 0.0002882253 \t Training Accuracy: 44.44 \tValidation Loss: 0.0732304036 \tValidation Accuracy 51.16\n",
      "Validation loss decreased (0.0732455764 --> 0.0732304036).\n",
      "Epoch: 248 \tTraining Loss: 0.0002878110 \t Training Accuracy: 44.59 \tValidation Loss: 0.0732163634 \tValidation Accuracy 51.17\n",
      "Validation loss decreased (0.0732304036 --> 0.0732163634).\n",
      "Epoch: 249 \tTraining Loss: 0.0002879359 \t Training Accuracy: 44.57 \tValidation Loss: 0.0732021553 \tValidation Accuracy 51.18\n",
      "Validation loss decreased (0.0732163634 --> 0.0732021553).\n",
      "Epoch: 250 \tTraining Loss: 0.0002880926 \t Training Accuracy: 44.58 \tValidation Loss: 0.0731835635 \tValidation Accuracy 51.19\n",
      "Validation loss decreased (0.0732021553 --> 0.0731835635).\n",
      "Epoch: 251 \tTraining Loss: 0.0002878162 \t Training Accuracy: 44.56 \tValidation Loss: 0.0731742636 \tValidation Accuracy 51.21\n",
      "Validation loss decreased (0.0731835635 --> 0.0731742636).\n",
      "Epoch: 252 \tTraining Loss: 0.0002875292 \t Training Accuracy: 44.59 \tValidation Loss: 0.0731587186 \tValidation Accuracy 51.23\n",
      "Validation loss decreased (0.0731742636 --> 0.0731587186).\n",
      "Epoch: 253 \tTraining Loss: 0.0002877394 \t Training Accuracy: 44.57 \tValidation Loss: 0.0731515412 \tValidation Accuracy 51.27\n",
      "Validation loss decreased (0.0731587186 --> 0.0731515412).\n",
      "Epoch: 254 \tTraining Loss: 0.0002876095 \t Training Accuracy: 44.70 \tValidation Loss: 0.0731259185 \tValidation Accuracy 51.26\n",
      "Validation loss decreased (0.0731515412 --> 0.0731259185).\n",
      "Epoch: 255 \tTraining Loss: 0.0002875252 \t Training Accuracy: 44.63 \tValidation Loss: 0.0731118256 \tValidation Accuracy 51.28\n",
      "Validation loss decreased (0.0731259185 --> 0.0731118256).\n",
      "Epoch: 256 \tTraining Loss: 0.0002875370 \t Training Accuracy: 44.64 \tValidation Loss: 0.0730970787 \tValidation Accuracy 51.29\n",
      "Validation loss decreased (0.0731118256 --> 0.0730970787).\n",
      "Epoch: 257 \tTraining Loss: 0.0002873508 \t Training Accuracy: 44.73 \tValidation Loss: 0.0730804311 \tValidation Accuracy 51.29\n",
      "Validation loss decreased (0.0730970787 --> 0.0730804311).\n",
      "Epoch: 258 \tTraining Loss: 0.0002872221 \t Training Accuracy: 44.72 \tValidation Loss: 0.0730649038 \tValidation Accuracy 51.30\n",
      "Validation loss decreased (0.0730804311 --> 0.0730649038).\n",
      "Epoch: 259 \tTraining Loss: 0.0002871717 \t Training Accuracy: 44.62 \tValidation Loss: 0.0730592235 \tValidation Accuracy 51.35\n",
      "Validation loss decreased (0.0730649038 --> 0.0730592235).\n",
      "Epoch: 260 \tTraining Loss: 0.0002872204 \t Training Accuracy: 44.69 \tValidation Loss: 0.0730364055 \tValidation Accuracy 51.34\n",
      "Validation loss decreased (0.0730592235 --> 0.0730364055).\n",
      "Epoch: 261 \tTraining Loss: 0.0002872920 \t Training Accuracy: 44.59 \tValidation Loss: 0.0730221446 \tValidation Accuracy 51.34\n",
      "Validation loss decreased (0.0730364055 --> 0.0730221446).\n",
      "Epoch: 262 \tTraining Loss: 0.0002872926 \t Training Accuracy: 44.75 \tValidation Loss: 0.0730104177 \tValidation Accuracy 51.36\n",
      "Validation loss decreased (0.0730221446 --> 0.0730104177).\n",
      "Epoch: 263 \tTraining Loss: 0.0002870758 \t Training Accuracy: 44.73 \tValidation Loss: 0.0729929825 \tValidation Accuracy 51.38\n",
      "Validation loss decreased (0.0730104177 --> 0.0729929825).\n",
      "Epoch: 264 \tTraining Loss: 0.0002870761 \t Training Accuracy: 44.72 \tValidation Loss: 0.0729811697 \tValidation Accuracy 51.39\n",
      "Validation loss decreased (0.0729929825 --> 0.0729811697).\n",
      "Epoch: 265 \tTraining Loss: 0.0002866651 \t Training Accuracy: 44.86 \tValidation Loss: 0.0729621180 \tValidation Accuracy 51.38\n",
      "Validation loss decreased (0.0729811697 --> 0.0729621180).\n",
      "Epoch: 266 \tTraining Loss: 0.0002868758 \t Training Accuracy: 44.78 \tValidation Loss: 0.0729453572 \tValidation Accuracy 51.39\n",
      "Validation loss decreased (0.0729621180 --> 0.0729453572).\n",
      "Epoch: 267 \tTraining Loss: 0.0002868558 \t Training Accuracy: 44.73 \tValidation Loss: 0.0729342834 \tValidation Accuracy 51.45\n",
      "Validation loss decreased (0.0729453572 --> 0.0729342834).\n",
      "Epoch: 268 \tTraining Loss: 0.0002868966 \t Training Accuracy: 44.82 \tValidation Loss: 0.0729143391 \tValidation Accuracy 51.43\n",
      "Validation loss decreased (0.0729342834 --> 0.0729143391).\n",
      "Epoch: 269 \tTraining Loss: 0.0002866216 \t Training Accuracy: 44.77 \tValidation Loss: 0.0729070672 \tValidation Accuracy 51.44\n",
      "Validation loss decreased (0.0729143391 --> 0.0729070672).\n",
      "Epoch: 270 \tTraining Loss: 0.0002866292 \t Training Accuracy: 44.75 \tValidation Loss: 0.0728943230 \tValidation Accuracy 51.47\n",
      "Validation loss decreased (0.0729070672 --> 0.0728943230).\n",
      "Epoch: 271 \tTraining Loss: 0.0002866972 \t Training Accuracy: 44.74 \tValidation Loss: 0.0728774380 \tValidation Accuracy 51.47\n",
      "Validation loss decreased (0.0728943230 --> 0.0728774380).\n",
      "Epoch: 272 \tTraining Loss: 0.0002861821 \t Training Accuracy: 44.86 \tValidation Loss: 0.0728653661 \tValidation Accuracy 51.51\n",
      "Validation loss decreased (0.0728774380 --> 0.0728653661).\n",
      "Epoch: 273 \tTraining Loss: 0.0002862937 \t Training Accuracy: 44.85 \tValidation Loss: 0.0728514370 \tValidation Accuracy 51.51\n",
      "Validation loss decreased (0.0728653661 --> 0.0728514370).\n",
      "Epoch: 274 \tTraining Loss: 0.0002861426 \t Training Accuracy: 44.84 \tValidation Loss: 0.0728386658 \tValidation Accuracy 51.52\n",
      "Validation loss decreased (0.0728514370 --> 0.0728386658).\n",
      "Epoch: 275 \tTraining Loss: 0.0002866657 \t Training Accuracy: 44.82 \tValidation Loss: 0.0728168298 \tValidation Accuracy 51.50\n",
      "Validation loss decreased (0.0728386658 --> 0.0728168298).\n",
      "Epoch: 276 \tTraining Loss: 0.0002863800 \t Training Accuracy: 44.90 \tValidation Loss: 0.0728045452 \tValidation Accuracy 51.52\n",
      "Validation loss decreased (0.0728168298 --> 0.0728045452).\n",
      "Epoch: 277 \tTraining Loss: 0.0002862030 \t Training Accuracy: 44.87 \tValidation Loss: 0.0727910831 \tValidation Accuracy 51.54\n",
      "Validation loss decreased (0.0728045452 --> 0.0727910831).\n",
      "Epoch: 278 \tTraining Loss: 0.0002859704 \t Training Accuracy: 44.92 \tValidation Loss: 0.0727771178 \tValidation Accuracy 51.55\n",
      "Validation loss decreased (0.0727910831 --> 0.0727771178).\n",
      "Epoch: 279 \tTraining Loss: 0.0002859146 \t Training Accuracy: 44.96 \tValidation Loss: 0.0727642372 \tValidation Accuracy 51.56\n",
      "Validation loss decreased (0.0727771178 --> 0.0727642372).\n",
      "Epoch: 280 \tTraining Loss: 0.0002860644 \t Training Accuracy: 44.91 \tValidation Loss: 0.0727472237 \tValidation Accuracy 51.56\n",
      "Validation loss decreased (0.0727642372 --> 0.0727472237).\n",
      "Epoch: 281 \tTraining Loss: 0.0002860501 \t Training Accuracy: 44.87 \tValidation Loss: 0.0727333417 \tValidation Accuracy 51.59\n",
      "Validation loss decreased (0.0727472237 --> 0.0727333417).\n",
      "Epoch: 282 \tTraining Loss: 0.0002860034 \t Training Accuracy: 44.91 \tValidation Loss: 0.0727228722 \tValidation Accuracy 51.59\n",
      "Validation loss decreased (0.0727333417 --> 0.0727228722).\n",
      "Epoch: 283 \tTraining Loss: 0.0002860801 \t Training Accuracy: 44.92 \tValidation Loss: 0.0727055643 \tValidation Accuracy 51.59\n",
      "Validation loss decreased (0.0727228722 --> 0.0727055643).\n",
      "Epoch: 284 \tTraining Loss: 0.0002856725 \t Training Accuracy: 44.96 \tValidation Loss: 0.0726912413 \tValidation Accuracy 51.61\n",
      "Validation loss decreased (0.0727055643 --> 0.0726912413).\n",
      "Epoch: 285 \tTraining Loss: 0.0002857531 \t Training Accuracy: 45.00 \tValidation Loss: 0.0726768473 \tValidation Accuracy 51.62\n",
      "Validation loss decreased (0.0726912413 --> 0.0726768473).\n",
      "Epoch: 286 \tTraining Loss: 0.0002857942 \t Training Accuracy: 44.88 \tValidation Loss: 0.0726661633 \tValidation Accuracy 51.64\n",
      "Validation loss decreased (0.0726768473 --> 0.0726661633).\n",
      "Epoch: 287 \tTraining Loss: 0.0002855669 \t Training Accuracy: 45.00 \tValidation Loss: 0.0726472664 \tValidation Accuracy 51.64\n",
      "Validation loss decreased (0.0726661633 --> 0.0726472664).\n",
      "Epoch: 288 \tTraining Loss: 0.0002856376 \t Training Accuracy: 44.99 \tValidation Loss: 0.0726325406 \tValidation Accuracy 51.64\n",
      "Validation loss decreased (0.0726472664 --> 0.0726325406).\n",
      "Epoch: 289 \tTraining Loss: 0.0002859953 \t Training Accuracy: 44.86 \tValidation Loss: 0.0726316358 \tValidation Accuracy 51.68\n",
      "Validation loss decreased (0.0726325406 --> 0.0726316358).\n",
      "Epoch: 290 \tTraining Loss: 0.0002857755 \t Training Accuracy: 45.01 \tValidation Loss: 0.0726156024 \tValidation Accuracy 51.68\n",
      "Validation loss decreased (0.0726316358 --> 0.0726156024).\n",
      "Epoch: 291 \tTraining Loss: 0.0002852570 \t Training Accuracy: 45.01 \tValidation Loss: 0.0726004348 \tValidation Accuracy 51.69\n",
      "Validation loss decreased (0.0726156024 --> 0.0726004348).\n",
      "Epoch: 292 \tTraining Loss: 0.0002854560 \t Training Accuracy: 45.02 \tValidation Loss: 0.0725871324 \tValidation Accuracy 51.69\n",
      "Validation loss decreased (0.0726004348 --> 0.0725871324).\n",
      "Epoch: 293 \tTraining Loss: 0.0002853357 \t Training Accuracy: 45.07 \tValidation Loss: 0.0725697405 \tValidation Accuracy 51.68\n",
      "Validation loss decreased (0.0725871324 --> 0.0725697405).\n",
      "Epoch: 294 \tTraining Loss: 0.0002855278 \t Training Accuracy: 45.02 \tValidation Loss: 0.0725627711 \tValidation Accuracy 51.71\n",
      "Validation loss decreased (0.0725697405 --> 0.0725627711).\n",
      "Epoch: 295 \tTraining Loss: 0.0002854556 \t Training Accuracy: 45.08 \tValidation Loss: 0.0725444170 \tValidation Accuracy 51.71\n",
      "Validation loss decreased (0.0725627711 --> 0.0725444170).\n",
      "Epoch: 296 \tTraining Loss: 0.0002854821 \t Training Accuracy: 45.14 \tValidation Loss: 0.0725360976 \tValidation Accuracy 51.73\n",
      "Validation loss decreased (0.0725444170 --> 0.0725360976).\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "early_stop = 0\n",
    "EARLY_STOP_COUNT = 10\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    running_correct_preds = 0\n",
    "    running_labels = 0\n",
    "    model.train()\n",
    "    # model by default is set to train\n",
    "    for batch_i, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "\n",
    "        dummy = torch.zeros((target.shape[0],num_classes)).type(torch.int64)\n",
    "        predictions = torch.sigmoid(output).detach().cpu()\n",
    "        predictions[predictions >= 0.5] = 1\n",
    "        predictions[predictions < 0.5] = 0\n",
    "        correctPreds = torch.where(((predictions > dummy) & (predictions == target.detach().cpu())),1,0)\n",
    "        running_correct_preds += torch.sum(correctPreds)        \n",
    "        running_labels += torch.sum(target)\n",
    "\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_accuracy = (running_correct_preds / running_labels) * 100\n",
    "\n",
    "    # Validate the Model\n",
    "    model.eval()\n",
    "    running_correct_preds = 0\n",
    "    running_labels = 0\n",
    "    for data, target in val_loader:\n",
    "        # Move tensor to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # Calculate accuracy on val set\n",
    "        dummy = torch.zeros((target.shape[0],num_classes)).type(torch.int64)\n",
    "        predictions = torch.sigmoid(output).detach().cpu()\n",
    "        predictions[predictions >= 0.5] = 1\n",
    "        predictions[predictions < 0.5] = 0\n",
    "        correctPreds = torch.where(((predictions > dummy) & (predictions == target.detach().cpu())),1,0)\n",
    "        running_correct_preds += torch.sum(correctPreds)        \n",
    "        running_labels += torch.sum(target)\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(val_loader.dataset)\n",
    "\n",
    "    # calculate validation accuracy\n",
    "    val_accuracy = (running_correct_preds/running_labels) * 100\n",
    "\n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.10f} \\t Training Accuracy: {:.2f} \\tValidation Loss: {:.10f} \\tValidation Accuracy {:.2f}'.format(\n",
    "        epoch, train_loss, train_accuracy, valid_loss, val_accuracy))\n",
    "    \n",
    "    # save training/validation statistics\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(valid_loss)    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss < valid_loss_min:\n",
    "        print('Validation loss decreased ({:.10f} --> {:.10f}).'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        # Update model state\n",
    "#         torch.save(model.state_dict(), os.path.join(model_filepath, 'scm_state.pt'))\n",
    "        valid_loss_min = valid_loss\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "    if early_stop >= EARLY_STOP_COUNT:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=80, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, MODEL_PATH_FULL)\n",
    "model = torch.load(MODEL_PATH_FULL)\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the classification accuracy of the trained model on the Val 2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = DatasetProcessing(DATA_PATH, TEST_IMG_PATH, TEST_ANN_PATH, transform = transformations, dataType = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_PATH_FULL)\n",
    "model.eval()\n",
    "\n",
    "num_classes = 80\n",
    "running_correct_preds = 0\n",
    "running_labels = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        images, lbls, bb, bblabels = test_set[i]\n",
    "\n",
    "        img = torch.clone(images)\n",
    "        lbl = torch.clone(lbls)\n",
    "        img = img.unsqueeze(0) \n",
    "        lbl = lbl.unsqueeze(0)\n",
    "\n",
    "        img, lbl = img.cuda(), lbl.cuda()\n",
    "\n",
    "        outputs = model(img)        \n",
    "\n",
    "        dummy = torch.zeros((lbl.shape[0],num_classes)).type(torch.int64)\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "        predictions[predictions >= 0.5] = 1\n",
    "        predictions[predictions < 0.5] = 0\n",
    "        correctPreds = torch.where(((predictions > dummy) & (predictions == lbl.detach().cpu())),1,0)\n",
    "        running_correct_preds += torch.sum(correctPreds)        \n",
    "        running_labels += torch.sum(lbl)\n",
    "\n",
    "print('Accuracy of the model on val 2017 images: %d %%' % (running_correct_preds / running_labels * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
